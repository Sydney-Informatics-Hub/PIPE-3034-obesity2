---
title: "Loading and exploring the data"
---

In this file, we start by loading and exploring the data for the obesity corpus.

```{r getData}
library(here)
library(janitor)
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
theme_set(theme_minimal())


read_cqpweb <- function(filename){
  read.csv(
    here("100_data_raw", filename), 
    skip = 3, sep = "\t") %>% 
    janitor::clean_names()
}

condition_first <- read_cqpweb("aoc_all_condition_first.txt")
person_first <- read_cqpweb("aoc_all_person_first.txt")

adj_obese <- read_cqpweb("aoc_all_obese_tagadjlemma.txt")
adj_overweight <- read_cqpweb("aoc_all_overweight_tagadjlemma.txt")
  
metadata <- read_csv(here("100_data_raw", "corpus_cqpweb_metadata.csv"))

condition_first_annotated <- inner_join(
  condition_first, metadata, by = c("text" = "article_id"))
person_first_annotated <- inner_join(
  person_first, metadata, by = c("text" = "article_id"))
```

Check that all `text` in the CQP web export file are found in the `article_id` of the metadata file. We ensure that we also show whether any `text`s have missing ids by using the `, useNA ="always"` argument.


```{r checkArticleID}
table(condition_first$text %in% metadata$article_id, useNA ="always")
table(person_first$text %in% metadata$article_id, useNA ="always")
table(adj_obese$text %in% metadata$article_id, useNA ="always")
table(adj_overweight$text %in% metadata$article_id, useNA ="always")
```

Yes, this is true for all of them.

## CQP-web vs metadata-annotated and Python-quantitated word counts

When carrying out modelling, it is often important to use data normalised to article word counts. This is dependent upon getting a correct word count for each article. Below, we compare article word counts from CQPWeb to those generated by Python and reported in the metadata in Lexis.


First, compare the counts from Python and the metadata:

```{r WC_python_metadata}
p <- condition_first_annotated %>%
  ggplot(aes(x = wordcount_total,
             y = wordcount_from_metatata)) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, col = "blue", lty = 2) +
  xlab("Word count, Python") + 
  ylab("Word count, metadata") 
plotly::ggplotly(p) 
```

The word counts are well correlated across all text lengths.

Next, we compare the word counts from CQP-web and the metadata:

```{r WC_cqp_metadata}
p <- condition_first_annotated %>%
  ggplot(aes(x = no_words_in_text,
             y = wordcount_from_metatata)) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, col = "blue", lty = 2) +
  xlab("Word count, Python") + 
  ylab("Word count, metadata") 
plotly::ggplotly(p) 
```

We can see that the longer the text, the more the counts do not match what is in the metadata (or counted via Python). This is most likely to CQP-Web counting punctuation as tokens, thereby with longer text more punctuation is added to each text.

To make this more apparent, we plot the difference between the metadata-provided and Python and CQP-web counts:


```{r}
condition_first_annotated %>%
  mutate(
    `Python - metadata` = (abs(wordcount_total - wordcount_from_metatata)),
    `CQPweb - metadata` = (abs(no_words_in_text - wordcount_from_metatata)),
    word_count_quartile = ntile(wordcount_from_metatata, 10)) %>%
  select(`Python - metadata`, `CQPweb - metadata`, word_count_quartile) %>%
  pivot_longer(cols = c(`Python - metadata`, `CQPweb - metadata`)) %>%
  ggplot(aes(x = as.factor(word_count_quartile), 
             y = value,
             fill = name)) + geom_boxplot() +
  labs(
    x = "Text length, decile, based on metadata supplied word count",
    y = "Absolute difference in word count between X and metadata-provided counts",
   caption = "The longer the text, the more the CQP-Web count diverges from that of the metadata (and Python)") + guides(fill=guide_legend(title="Difference"))
  
```

**CONCLUSION: Use the Python-generated total word count for calculating normalised frequencies. This also means we cannot use the provided normalised frequencies from CQPweb.**


